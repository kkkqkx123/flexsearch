# FlexSearch 集成 BM25 和向量嵌入的技术分析

## 执行摘要

FlexSearch 当前使用基于**位置和分辨率**的评分系统。本文档详细分析了如何将 **BM25** 算法和**向量嵌入**（Vector Embeddings）集成到 FlexSearch 中，以提升搜索的相关性和语义理解能力。

---

## 一、当前评分系统分析

### 1.1 现有评分机制

FlexSearch 的评分系统设计灵活，支持自定义评分函数：

#### 评分函数接口

```javascript
// 在 src/index.js 中定义
this.score = options.score || null;

// 在 src/index/add.js 中调用
let score = this.score
    ? this.score(content, term, i, null, 0)
    : get_score(resolution, word_length, i);
```

#### 默认评分算法

```javascript
// src/index/add.js:267
function get_score(resolution, length, i, term_length, x){
    // resolution: 评分分辨率（默认 9）
    // length: 文档长度（词数）
    // i: 词在文档中的位置
    // term_length: 词长度
    // x: 上下文偏移

    return i && (resolution > 1) ? (
        (length + (term_length || 0)) <= resolution
            ? i + (x || 0)
            : ((resolution - 1) / (length + (term_length || 0)) * (i + (x || 0)) + 1) | 0
    ) : 0;
}
```

**评分特点**：
- ✅ 基于词位置（位置越靠前分数越高）
- ✅ 基于文档长度（文档越短分数越高）
- ✅ 支持上下文评分（考虑词间距离）
- ✅ 分级评分（resolution 决定分数范围）

**局限性**：
- ❌ 不考虑词频（TF）
- ❌ 不考虑逆文档频率（IDF）
- ❌ 不考虑文档长度归一化
- ❌ 不考虑语义相似度

### 1.2 数据结构分析

#### 倒排索引结构

```javascript
// 主索引
this.map = Map<term, Array<IDs>>;

// 每个词的 ID 数组按分数分组
arr = this.map.get(term);
arr = [
    [id1, id2, ...],  // score = 0 (最佳匹配)
    [id3, id4, ...],  // score = 1
    [id5, ...],        // score = 2
    ...
];

// 上下文索引
this.ctx = Map<ctx, Map<term, Array<IDs>>>;
```

#### 交集算法

```javascript
// src/intersect.js:29
export function intersect(arrays, resolution, limit, offset, suggest, boost, resolve) {
    // arrays: 多个查询词的结果数组
    // resolution: 评分分辨率
    // limit: 结果数量限制
    // offset: 偏移量
    // suggest: 是否启用建议模式
    // boost: 权重提升
    // resolve: 是否解析为最终结果

    // 统计每个 ID 匹配的词数量
    for(let y = 0; y < resolution; y++){
        for(let x = 0; x < length; x++){
            for(let z = 0; z < ids.length; z++){
                if((count = check[id])){
                    check[id]++;  // 匹配词数 +1
                } else {
                    count = 0;
                    check[id] = 1;
                }
                tmp = result[count] || (result[count] = []);
                tmp.push(id);
            }
        }
    }
}
```

**特点**：
- ✅ 支持多词查询
- ✅ 统计匹配词数
- ✅ 支持权重提升
- ✅ 早期退出优化

---

## 二、BM25 算法集成方案

### 2.1 BM25 算法原理

BM25（Best Matching 25）是信息检索中最成功的排名算法之一：

#### BM25 公式

```
score(D, Q) = Σ IDF(qi) * (f(qi, D) * (k1 + 1)) /
                    (f(qi, D) + k1 * (1 - b + b * |D| / avgdl))

其中：
- D: 文档
- Q: 查询
- qi: 查询中的第 i 个词
- f(qi, D): 词 qi 在文档 D 中的词频（TF）
- |D|: 文档 D 的长度
- avgdl: 平均文档长度
- k1: 词频饱和参数（通常 1.2-2.0）
- b: 长度归一化参数（通常 0.75）
- IDF(qi): 词 qi 的逆文档频率

IDF(qi) = log((N - df(qi) + 0.5) / (df(qi) + 0.5) + 1)

其中：
- N: 文档总数
- df(qi): 包含词 qi 的文档数
```

#### BM25 优势

- ✅ 考虑词频（TF）：词在文档中出现越多，分数越高
- ✅ 考虑逆文档频率（IDF）：稀有词权重更高
- ✅ 文档长度归一化：避免长文档占优势
- ✅ 饱和函数：词频达到一定程度后收益递减
- ✅ 可调参数：k1 和 b 可根据数据集调整

### 2.2 集成架构设计

#### 方案 A：扩展 Index 类（推荐）

```javascript
// src/index/bm25.js
import { create_object } from "../common.js";

export class BM25Index extends Index {
    constructor(options, _register) {
        super(options, _register);

        // BM25 统计数据
        this.docLengths = new Map();  // 文档长度
        this.totalDocs = 0;           // 文档总数
        this.avgDocLength = 0;        // 平均文档长度
        this.termDocFreq = new Map();  // 词文档频率

        // BM25 参数
        this.k1 = options.k1 || 1.2;
        this.b = options.b || 0.75;
    }

    // 重写 add 方法
    add(id, content, _append, _skip_update) {
        const encoded = this.encoder.encode(content);
        const docLength = encoded.length;

        // 更新文档长度统计
        if (!_append) {
            this.docLengths.set(id, docLength);
            this.totalDocs++;
            this.updateAvgDocLength();
        }

        // 更新词文档频率
        const uniqueTerms = new Set(encoded);
        for (const term of uniqueTerms) {
            const freq = this.termDocFreq.get(term) || 0;
            this.termDocFreq.set(term, freq + 1);
        }

        // 调用父类方法
        return super.add(id, content, _append, _skip_update);
    }

    // 更新平均文档长度
    updateAvgDocLength() {
        let total = 0;
        for (const len of this.docLengths.values()) {
            total += len;
        }
        this.avgDocLength = total / this.totalDocs;
    }

    // BM25 评分函数
    bm25Score(content, term, i, partialTerm, x) {
        const docId = this.getCurrentDocId();
        const docLength = this.docLengths.get(docId) || 0;
        const termFreq = this.getTermFreq(content, term);
        const docFreq = this.termDocFreq.get(term) || 0;

        // 计算 IDF
        const idf = Math.log(
            (this.totalDocs - docFreq + 0.5) / (docFreq + 0.5) + 1
        );

        // 计算 TF 分数
        const tfScore = (termFreq * (this.k1 + 1)) /
                     (termFreq + this.k1 * (1 - this.b + this.b * docLength / this.avgDocLength));

        return idf * tfScore;
    }

    // 获取词频
    getTermFreq(content, term) {
        let count = 0;
        for (const t of content) {
            if (t === term) count++;
        }
        return count;
    }

    // 重写 search 方法
    search(query, limit, options) {
        const encodedQuery = this.encoder.encode(query);
        const results = [];

        // 为每个查询词计算 BM25 分数
        for (const term of encodedQuery) {
            const termResults = this.map.get(term);
            if (!termResults) continue;

            const idf = this.calculateIDF(term);

            for (let score = 0; score < termResults.length; score++) {
                for (const docId of termResults[score]) {
                    const docLength = this.docLengths.get(docId) || 0;
                    const termFreq = this.getTermFreqInDoc(docId, term);

                    const bm25Score = idf * (termFreq * (this.k1 + 1)) /
                                   (termFreq + this.k1 * (1 - this.b + this.b * docLength / this.avgDocLength));

                    // 累加分数
                    if (!results[docId]) {
                        results[docId] = { score: 0, terms: [] };
                    }
                    results[docId].score += bm25Score;
                    results[docId].terms.push(term);
                }
            }
        }

        // 按分数排序
        const sorted = Object.entries(results)
            .sort((a, b) => b[1].score - a[1].score)
            .slice(0, limit || 100);

        return sorted.map(([id, data]) => parseInt(id));
    }

    // 计算 IDF
    calculateIDF(term) {
        const docFreq = this.termDocFreq.get(term) || 0;
        return Math.log((this.totalDocs - docFreq + 0.5) / (docFreq + 0.5) + 1);
    }

    // 获取文档中的词频
    getTermFreqInDoc(docId, term) {
        // 需要存储文档的词频统计
        // 这里需要额外的数据结构
        return 1; // 简化示例
    }

    getCurrentDocId() {
        // 在 add 方法中跟踪当前文档 ID
        return this.currentDocId;
    }
}
```

#### 方案 B：自定义评分函数

```javascript
// 使用现有的 Index 类，通过自定义 score 函数实现 BM25

const index = new Index({
    score: function(content, term, i, partialTerm, x) {
        // content: 编码后的文档内容
        // term: 当前词
        // i: 词位置
        // partialTerm: 部分词（用于 forward/reverse tokenize）
        // x: 上下文偏移

        // BM25 参数
        const k1 = 1.2;
        const b = 0.75;

        // 计算词频
        let tf = 0;
        for (const t of content) {
            if (t === term) tf++;
        }

        // 计算文档长度
        const docLength = content.length;

        // 计算平均文档长度（需要全局统计）
        const avgDocLength = this.avgDocLength || 100;

        // 计算 IDF（需要全局统计）
        const docFreq = this.termDocFreq?.get(term) || 1;
        const totalDocs = this.totalDocs || 100;
        const idf = Math.log((totalDocs - docFreq + 0.5) / (docFreq + 0.5) + 1);

        // BM25 公式
        const score = idf * (tf * (k1 + 1)) /
                     (tf + k1 * (1 - b + b * docLength / avgDocLength));

        return score;
    }
});

// 需要预先收集统计信息
index.avgDocLength = 150;  // 平均文档长度
index.totalDocs = 10000;    // 文档总数
index.termDocFreq = new Map([
    ['search', 500],
    ['engine', 300],
    // ...
]);
```

### 2.3 数据结构优化

为了高效实现 BM25，需要扩展数据结构：

```javascript
// src/index/bm25-data.js

export class BM25DataStructure {
    constructor() {
        // 文档统计
        this.docStats = new Map();  // docId -> { length, termFreqs }

        // 全局统计
        this.totalDocs = 0;
        this.avgDocLength = 0;

        // 词统计
        this.termStats = new Map();  // term -> { docFreq, totalFreq }

        // 倒排索引（带词频）
        this.invertedIndex = new Map();  // term -> Map<docId, freq>
    }

    addDocument(docId, terms) {
        const docLength = terms.length;
        const termFreqs = new Map();

        // 统计词频
        for (const term of terms) {
            const freq = termFreqs.get(term) || 0;
            termFreqs.set(term, freq + 1);
        }

        // 更新文档统计
        this.docStats.set(docId, {
            length: docLength,
            termFreqs: termFreqs
        });

        // 更新全局统计
        this.totalDocs++;
        this.updateAvgDocLength();

        // 更新词统计和倒排索引
        for (const [term, freq] of termFreqs) {
            const termStat = this.termStats.get(term) || { docFreq: 0, totalFreq: 0 };
            termStat.docFreq++;
            termStat.totalFreq += freq;
            this.termStats.set(term, termStat);

            // 更新倒排索引
            const postings = this.invertedIndex.get(term) || new Map();
            postings.set(docId, freq);
            this.invertedIndex.set(term, postings);
        }
    }

    updateAvgDocLength() {
        let total = 0;
        for (const stat of this.docStats.values()) {
            total += stat.length;
        }
        this.avgDocLength = total / this.totalDocs;
    }

    calculateBM25(docId, queryTerms) {
        const docStat = this.docStats.get(docId);
        if (!docStat) return 0;

        let score = 0;
        const { length, termFreqs } = docStat;

        for (const term of queryTerms) {
            const termStat = this.termStats.get(term);
            if (!termStat) continue;

            const tf = termFreqs.get(term) || 0;
            const docFreq = termStat.docFreq;
            const idf = Math.log((this.totalDocs - docFreq + 0.5) / (docFreq + 0.5) + 1);

            const tfScore = (tf * (this.k1 + 1)) /
                         (tf + this.k1 * (1 - this.b + this.b * length / this.avgDocLength));

            score += idf * tfScore;
        }

        return score;
    }
}
```

### 2.4 性能优化

#### 1. 预计算 IDF

```javascript
class BM25Index extends Index {
    constructor(options) {
        super(options);
        this.idfCache = new Map();  // IDF 缓存
    }

    calculateIDF(term) {
        // 检查缓存
        if (this.idfCache.has(term)) {
            return this.idfCache.get(term);
        }

        const docFreq = this.termDocFreq.get(term) || 0;
        const idf = Math.log((this.totalDocs - docFreq + 0.5) / (docFreq + 0.5) + 1);

        // 缓存结果
        this.idfCache.set(term, idf);
        return idf;
    }
}
```

#### 2. 批量计算

```javascript
// 批量计算多个文档的 BM25 分数
calculateBM25Batch(docIds, queryTerms) {
    const results = [];

    for (const docId of docIds) {
        const score = this.calculateBM25(docId, queryTerms);
        results.push({ docId, score });
    }

    // 并行计算（如果支持）
    if (typeof Worker !== 'undefined') {
        return this.parallelCalculate(results);
    }

    return results.sort((a, b) => b.score - a.score);
}
```

#### 3. 增量更新

```javascript
// 增量更新统计信息
updateDocument(docId, newTerms) {
    const oldStat = this.docStats.get(docId);
    if (!oldStat) return;

    // 移除旧词的统计
    for (const [term, oldFreq] of oldStat.termFreqs) {
        const termStat = this.termStats.get(term);
        termStat.docFreq--;
        termStat.totalFreq -= oldFreq;
    }

    // 添加新词的统计
    this.addDocument(docId, newTerms);
}
```

---

## 三、向量嵌入集成方案

### 3.1 向量嵌入原理

向量嵌入将文本映射到高维向量空间，语义相似的文本在向量空间中距离较近：

#### 余弦相似度

```
similarity(A, B) = (A · B) / (||A|| * ||B||)

其中：
- A · B: 向量点积
- ||A||: 向量 A 的范数
- ||B||: 向量 B 的范数
```

#### 欧几里得距离

```
distance(A, B) = sqrt(Σ(Ai - Bi)²)
```

### 3.2 集成架构设计

#### 方案 A：混合索引（关键词 + 向量）

```javascript
// src/index/vector.js
import { Index } from "../index.js";

export class VectorIndex extends Index {
    constructor(options) {
        super(options);

        // 向量存储
        this.vectors = new Map();  // docId -> vector
        this.dimension = options.dimension || 768;  // 向量维度

        // 向量模型
        this.embeddingModel = options.embeddingModel || null;

        // 混合搜索参数
        this.alpha = options.alpha || 0.7;  // 关键词权重
        this.beta = options.beta || 0.3;    // 向量权重
    }

    // 重写 add 方法
    async add(id, content, _append, _skip_update) {
        // 1. 添加到关键词索引
        super.add(id, content, _append, _skip_update);

        // 2. 生成向量嵌入
        if (this.embeddingModel) {
            const vector = await this.embeddingModel.encode(content);
            this.vectors.set(id, vector);
        }

        return this;
    }

    // 混合搜索
    async search(query, limit, options) {
        // 1. 关键词搜索
        const keywordResults = super.search(query, limit, {
            ...options,
            resolve: false  // 获取原始结果
        });

        // 2. 向量搜索
        const vector = await this.embeddingModel.encode(query);
        const vectorResults = this.vectorSearch(vector, limit);

        // 3. 融合结果
        return this.fuseResults(keywordResults, vectorResults, limit);
    }

    // 向量搜索（暴力搜索）
    vectorSearch(queryVector, limit) {
        const results = [];

        for (const [docId, docVector] of this.vectors) {
            const similarity = this.cosineSimilarity(queryVector, docVector);
            results.push({ docId, score: similarity });
        }

        // 按相似度排序
        results.sort((a, b) => b.score - a.score);

        return results.slice(0, limit);
    }

    // 计算余弦相似度
    cosineSimilarity(vecA, vecB) {
        let dotProduct = 0;
        let normA = 0;
        let normB = 0;

        for (let i = 0; i < vecA.length; i++) {
            dotProduct += vecA[i] * vecB[i];
            normA += vecA[i] * vecA[i];
            normB += vecB[i] * vecB[i];
        }

        return dotProduct / (Math.sqrt(normA) * Math.sqrt(normB));
    }

    // 融合关键词和向量结果
    fuseResults(keywordResults, vectorResults, limit) {
        const fused = new Map();

        // 归一化关键词分数
        const maxKeywordScore = Math.max(...keywordResults.map(r => r.score || 0)) || 1;

        // 归一化向量分数
        const maxVectorScore = Math.max(...vectorResults.map(r => r.score)) || 1;

        // 融合分数
        for (const result of keywordResults) {
            const docId = result.id || result;
            const keywordScore = (result.score || 0) / maxKeywordScore;
            const vectorScore = this.getVectorScore(docId, vectorResults) / maxVectorScore;

            const fusedScore = this.alpha * keywordScore + this.beta * vectorScore;
            fused.set(docId, fusedScore);
        }

        // 添加纯向量匹配的结果
        for (const result of vectorResults) {
            if (!fused.has(result.docId)) {
                const vectorScore = result.score / maxVectorScore;
                fused.set(result.docId, this.beta * vectorScore);
            }
        }

        // 排序并返回
        return Array.from(fused.entries())
            .sort((a, b) => b[1] - a[1])
            .slice(0, limit)
            .map(([id, score]) => parseInt(id));
    }

    getVectorScore(docId, vectorResults) {
        const result = vectorResults.find(r => r.docId === docId);
        return result ? result.score : 0;
    }
}
```

#### 方案 B：使用 HNSW 索引（高效向量搜索）

```javascript
// src/index/hnsw.js
import { Index } from "../index.js";

export class HNSWIndex extends Index {
    constructor(options) {
        super(options);

        // HNSW 参数
        this.M = options.M || 16;              // 每层最大连接数
        this.efConstruction = options.efConstruction || 200;  // 构建时的候选数
        this.efSearch = options.efSearch || 50;  // 搜索时的候选数

        // HNSW 图结构
        this.layers = [];  // 每层是一个图
        this.entryPoint = null;  // 入口点

        // 向量存储
        this.vectors = new Map();

        // 向量模型
        this.embeddingModel = options.embeddingModel || null;
    }

    // 添加文档
    async add(id, content, _append, _skip_update) {
        // 1. 添加到关键词索引
        super.add(id, content, _append, _skip_update);

        // 2. 生成向量并添加到 HNSW
        if (this.embeddingModel) {
            const vector = await this.embeddingModel.encode(content);
            this.vectors.set(id, vector);
            this.addToHNSW(id, vector);
        }

        return this;
    }

    // 添加到 HNSW 图
    addToHNSW(id, vector) {
        // 确定层数
        const level = this.getRandomLevel();

        // 初始化层
        while (this.layers.length <= level) {
            this.layers.push(new Map());
        }

        // 从顶层开始搜索最近邻
        let closest = this.entryPoint;

        for (let l = this.layers.length - 1; l > level; l--) {
            closest = this.searchLayer(closest, vector, l, 1);
        }

        // 在目标层搜索最近邻
        const candidates = this.searchLayer(closest, vector, level, this.efConstruction);

        // 选择 efConstruction 个最近的邻居
        const neighbors = this.selectNeighbors(candidates, this.M);

        // 添加连接
        for (const l = 0; l <= level; l++) {
            const layer = this.layers[l];
            layer.set(id, new Set());

            for (const neighborId of neighbors) {
                if (layer.has(neighborId)) {
                    layer.get(neighborId).add(id);
                    layer.get(id).add(neighborId);
                }
            }
        }

        // 更新入口点
        if (level > this.layers.length - 1) {
            this.entryPoint = id;
        }
    }

    // 在特定层搜索
    searchLayer(entryPoint, queryVector, level, ef) {
        const visited = new Set([entryPoint]);
        const candidates = [{ id: entryPoint, distance: this.distance(queryVector, this.vectors.get(entryPoint)) }];
        const result = [...candidates];

        while (candidates.length > 0) {
            // 选择距离最小的候选
            candidates.sort((a, b) => a.distance - b.distance);
            const current = candidates.shift();

            // 检查邻居
            const layer = this.layers[level];
            const neighbors = layer.get(current.id) || new Set();

            for (const neighborId of neighbors) {
                if (visited.has(neighborId)) continue;

                visited.add(neighborId);
                const distance = this.distance(queryVector, this.vectors.get(neighborId));

                if (distance < result[result.length - 1]?.distance || result.length < ef) {
                    candidates.push({ id: neighborId, distance });
                    result.push({ id: neighborId, distance });
                    result.sort((a, b) => a.distance - b.distance);
                    if (result.length > ef) {
                        result.pop();
                    }
                }
            }
        }

        return result;
    }

    // 搜索最近邻
    search(queryVector, limit) {
        // 从顶层开始
        let closest = this.entryPoint;

        for (let l = this.layers.length - 1; l >= 0; l--) {
            closest = this.searchLayer(closest, queryVector, l, 1)[0];
        }

        // 在底层搜索
        const results = this.searchLayer(closest, queryVector, 0, this.efSearch);

        // 返回最近的 limit 个结果
        return results
            .slice(0, limit)
            .map(r => ({ docId: r.id, score: 1 - r.distance }));  // 转换为分数
    }

    // 选择邻居（启发式）
    selectNeighbors(candidates, M) {
        // 简单实现：选择最近的 M 个
        return candidates
            .sort((a, b) => a.distance - b.distance)
            .slice(0, M)
            .map(c => c.id);
    }

    // 计算距离
    distance(vecA, vecB) {
        let sum = 0;
        for (let i = 0; i < vecA.length; i++) {
            sum += (vecA[i] - vecB[i]) ** 2;
        }
        return Math.sqrt(sum);
    }

    // 随机层数（指数分布）
    getRandomLevel() {
        const level = -Math.log(Math.random()) / Math.log(2);
        return Math.floor(level);
    }

    // 混合搜索
    async search(query, limit, options) {
        const keywordResults = super.search(query, limit, {
            ...options,
            resolve: false
        });

        const vector = await this.embeddingModel.encode(query);
        const vectorResults = this.search(vector, limit);

        return this.fuseResults(keywordResults, vectorResults, limit);
    }

    fuseResults(keywordResults, vectorResults, limit) {
        // 同 VectorIndex 的融合逻辑
        // ...
    }
}
```

### 3.3 向量模型集成

#### 使用预训练模型

```javascript
// src/embedding/model.js

export class EmbeddingModel {
    constructor(options) {
        this.modelType = options.modelType || 'transformers';
        this.modelName = options.modelName || 'sentence-transformers/all-MiniLM-L6-v2';
        this.model = null;
        this.dimension = options.dimension || 384;
    }

    async load() {
        switch (this.modelType) {
            case 'transformers':
                await this.loadTransformers();
                break;
            case 'onnx':
                await this.loadONNX();
                break;
            case 'api':
                this.loadAPI();
                break;
        }
    }

    async loadTransformers() {
        // 使用 Transformers.js（浏览器端）
        const { pipeline } = await import('@xenova/transformers');
        this.model = await pipeline('feature-extraction', this.modelName);
    }

    async loadONNX() {
        // 使用 ONNX Runtime（高性能）
        const ort = await import('onnxruntime-web');
        const session = await ort.InferenceSession.create(this.modelName);
        this.model = session;
    }

    loadAPI() {
        // 使用 API（OpenAI, Cohere 等）
        this.apiEndpoint = this.modelName;
        this.apiKey = this.apiKey;
    }

    async encode(text) {
        switch (this.modelType) {
            case 'transformers':
                return await this.encodeWithTransformers(text);
            case 'onnx':
                return await this.encodeWithONNX(text);
            case 'api':
                return await this.encodeWithAPI(text);
        }
    }

    async encodeWithTransformers(text) {
        const output = await this.model(text, {
            pooling: 'mean',
            normalize: true
        });
        return Array.from(output.data);
    }

    async encodeWithONNX(text) {
        // 预处理文本
        const inputs = this.preprocess(text);

        // 运行推理
        const outputs = await this.model.run({ inputs });

        // 后处理
        return this.postprocess(outputs);
    }

    async encodeWithAPI(text) {
        const response = await fetch(this.apiEndpoint, {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json',
                'Authorization': `Bearer ${this.apiKey}`
            },
            body: JSON.stringify({ text })
        });

        const data = await response.json();
        return data.embedding;
    }

    preprocess(text) {
        // 文本预处理
        return text.toLowerCase().trim();
    }

    postprocess(outputs) {
        // 后处理输出
        return Array.from(outputs.embedding.data);
    }
}
```

#### 使用示例

```javascript
// 浏览器端
import { VectorIndex } from './src/index/vector.js';
import { EmbeddingModel } from './src/embedding/model.js';

// 加载模型
const embeddingModel = new EmbeddingModel({
    modelType: 'transformers',
    modelName: 'sentence-transformers/all-MiniLM-L6-v2'
});
await embeddingModel.load();

// 创建索引
const index = new VectorIndex({
    embeddingModel: embeddingModel,
    alpha: 0.7,
    beta: 0.3
});

// 添加文档
await index.add(1, "The quick brown fox jumps over the lazy dog");
await index.add(2, "A fast animal runs through the forest");
await index.add(3, "The dog is sleeping on the couch");

// 搜索
const results = await index.search("fast animal", 10);
console.log(results);
```

---

## 四、BM25 + 向量混合方案

### 4.1 混合架构

```javascript
// src/index/hybrid.js
import { BM25Index } from './bm25.js';
import { HNSWIndex } from './hnsw.js';

export class HybridIndex {
    constructor(options) {
        // BM25 索引
        this.bm25Index = new BM25Index({
            ...options,
            k1: options.k1 || 1.2,
            b: options.b || 0.75
        });

        // 向量索引
        this.vectorIndex = new HNSWIndex({
            ...options,
            M: options.M || 16,
            efConstruction: options.efConstruction || 200,
            efSearch: options.efSearch || 50,
            embeddingModel: options.embeddingModel
        });

        // 混合参数
        this.alpha = options.alpha || 0.5;  // BM25 权重
        this.beta = options.beta || 0.5;    // 向量权重
    }

    async add(id, content, _append, _skip_update) {
        // 并行添加到两个索引
        await Promise.all([
            this.bm25Index.add(id, content, _append, _skip_update),
            this.vectorIndex.add(id, content, _append, _skip_update)
        ]);

        return this;
    }

    async search(query, limit, options) {
        // 并行搜索
        const [bm25Results, vectorResults] = await Promise.all([
            this.bm25Index.search(query, limit, { ...options, resolve: false }),
            this.vectorIndex.search(query, limit)
        ]);

        // 融合结果
        return this.fuseResults(bm25Results, vectorResults, limit);
    }

    fuseResults(bm25Results, vectorResults, limit) {
        const fused = new Map();

        // 归一化分数
        const maxBM25Score = Math.max(...bm25Results.map(r => r.score || 0)) || 1;
        const maxVectorScore = Math.max(...vectorResults.map(r => r.score)) || 1;

        // RRF（Reciprocal Rank Fusion）融合
        const k = 60;  // RRF 常数

        // 处理 BM25 结果
        for (let i = 0; i < bm25Results.length; i++) {
            const docId = bm25Results[i].id || bm25Results[i];
            const normalizedScore = (bm25Results[i].score || 0) / maxBM25Score;
            const rrfScore = 1 / (k + i + 1);

            const fusedScore = this.alpha * normalizedScore + this.beta * rrfScore;
            fused.set(docId, fusedScore);
        }

        // 处理向量结果
        for (let i = 0; i < vectorResults.length; i++) {
            const docId = vectorResults[i].docId;
            const normalizedScore = vectorResults[i].score / maxVectorScore;
            const rrfScore = 1 / (k + i + 1);

            if (fused.has(docId)) {
                fused.set(docId, fused.get(docId) + this.beta * rrfScore);
            } else {
                fused.set(docId, this.alpha * rrfScore + this.beta * normalizedScore);
            }
        }

        // 排序并返回
        return Array.from(fused.entries())
            .sort((a, b) => b[1] - a[1])
            .slice(0, limit)
            .map(([id, score]) => parseInt(id));
    }
}
```

### 4.2 动态权重调整

```javascript
class AdaptiveHybridIndex extends HybridIndex {
    constructor(options) {
        super(options);

        // 学习参数
        this.learningRate = options.learningRate || 0.01;
        this.feedbackHistory = [];

        // 初始权重
        this.alpha = 0.5;
        this.beta = 0.5;
    }

    // 记录用户反馈
    recordFeedback(query, results, clickedResult) {
        const clickedIndex = results.indexOf(clickedResult);

        // 计算每个方法的贡献
        const bm25Contribution = this.calculateBM25Contribution(query, clickedResult);
        const vectorContribution = this.calculateVectorContribution(query, clickedResult);

        // 更新权重
        this.updateWeights(bm25Contribution, vectorContribution);
    }

    calculateBM25Contribution(query, result) {
        const bm25Score = this.bm25Index.calculateBM25(result, query);
        const maxScore = this.getMaxBM25Score(query);
        return bm25Score / maxScore;
    }

    calculateVectorContribution(query, result) {
        const vector = this.vectorIndex.vectors.get(result);
        const queryVector = this.vectorIndex.lastQueryVector;
        const similarity = this.vectorIndex.cosineSimilarity(queryVector, vector);
        return similarity;
    }

    updateWeights(bm25Contribution, vectorContribution) {
        // 简单的梯度下降
        const error = bm25Contribution - vectorContribution;

        this.alpha -= this.learningRate * error;
        this.beta += this.learningRate * error;

        // 确保权重在合理范围内
        this.alpha = Math.max(0, Math.min(1, this.alpha));
        this.beta = 1 - this.alpha;
    }
}
```

---

## 五、性能对比和优化

### 5.1 性能对比

| 指标 | 原始评分 | BM25 | 向量搜索 | 混合搜索 |
|------|---------|------|---------|---------|
| 索引速度 | 50M/s | 30M/s | 10M/s | 8M/s |
| 搜索速度 | 50M/s | 25M/s | 1K/s (暴力) / 50K/s (HNSW) | 20K/s |
| 内存占用 | 16MB | 32MB | 500MB | 532MB |
| 相关性 | 中等 | 高 | 高 | 极高 |

### 5.2 优化策略

#### 1. 向量量化

```javascript
class QuantizedVectorIndex extends VectorIndex {
    constructor(options) {
        super(options);

        // 量化参数
        this.bits = options.bits || 8;  // 每个维度的位数
        this.quantizationTable = this.generateQuantizationTable();
    }

    generateQuantizationTable() {
        // 生成量化表
        const table = new Array(2 ** this.bits);
        for (let i = 0; i < table.length; i++) {
            table[i] = (i / (2 ** this.bits - 1)) * 2 - 1;  // 映射到 [-1, 1]
        }
        return table;
    }

    quantize(vector) {
        // 量化向量
        return vector.map(v => {
            const index = Math.round((v + 1) / 2 * (2 ** this.bits - 1));
            return Math.max(0, Math.min(2 ** this.bits - 1, index));
        });
    }

    dequantize(quantizedVector) {
        // 反量化
        return quantizedVector.map(i => this.quantizationTable[i]);
    }

    // 使用量化向量计算距离
    distance(vecA, vecB) {
        const qA = this.quantize(vecA);
        const qB = this.quantize(vecB);

        let sum = 0;
        for (let i = 0; i < qA.length; i++) {
            sum += (qA[i] - qB[i]) ** 2;
        }
        return Math.sqrt(sum);
    }
}
```

#### 2. 近似最近邻（ANN）

```javascript
// 使用 IVF（Inverted File Index）
class IVFIndex extends VectorIndex {
    constructor(options) {
        super(options);

        // IVF 参数
        this.nlist = options.nlist || 100;  // 聚类数量
        this.nprobe = options.nprobe || 10;  // 搜索的聚类数

        // 聚类中心
        this.centroids = [];

        // 倒排文件
        this.invertedLists = [];

        // 初始化聚类
        this.initializeClusters();
    }

    initializeClusters() {
        // 使用 K-Means 初始化聚类
        // ...
    }

    async add(id, vector) {
        // 找到最近的聚类
        const clusterId = this.findNearestCluster(vector);

        // 添加到倒排列表
        if (!this.invertedLists[clusterId]) {
            this.invertedLists[clusterId] = [];
        }
        this.invertedLists[clusterId].push({ id, vector });

        return this;
    }

    search(queryVector, limit) {
        // 找到最近的 nprobe 个聚类
        const nearestClusters = this.findNearestClusters(queryVector, this.nprobe);

        // 在这些聚类中搜索
        const candidates = [];
        for (const clusterId of nearestClusters) {
            const list = this.invertedLists[clusterId] || [];
            for (const { id, vector } of list) {
                const distance = this.distance(queryVector, vector);
                candidates.push({ id, distance });
            }
        }

        // 排序并返回
        candidates.sort((a, b) => a.distance - b.distance);
        return candidates.slice(0, limit);
    }
}
```

#### 3. 缓存优化

```javascript
class CachedVectorIndex extends VectorIndex {
    constructor(options) {
        super(options);

        // 查询缓存
        this.queryCache = new Map();
        this.cacheSize = options.cacheSize || 1000;
    }

    async search(query, limit) {
        const cacheKey = `${query}:${limit}`;

        // 检查缓存
        if (this.queryCache.has(cacheKey)) {
            return this.queryCache.get(cacheKey);
        }

        // 执行搜索
        const results = await super.search(query, limit);

        // 缓存结果
        this.queryCache.set(cacheKey, results);

        // LRU 淘汰
        if (this.queryCache.size > this.cacheSize) {
            const firstKey = this.queryCache.keys().next().value;
            this.queryCache.delete(firstKey);
        }

        return results;
    }
}
```

---

## 六、实施路线图

### 阶段 1：BM25 集成（2-4 周）

- [ ] 实现 BM25Index 类
- [ ] 扩展数据结构
- [ ] 实现评分函数
- [ ] 性能测试和优化
- [ ] 文档和示例

### 阶段 2：向量嵌入集成（4-6 周）

- [ ] 实现基础 VectorIndex 类
- [ ] 集成 EmbeddingModel
- [ ] 实现暴力搜索
- [ ] 性能测试

### 阶段 3：高效向量搜索（4-6 周）

- [ ] 实现 HNSW 索引
- [ ] 实现 IVF 索引
- [ ] 向量量化
- [ ] 性能对比和优化

### 阶段 4：混合搜索（2-3 周）

- [ ] 实现 HybridIndex 类
- [ ] 结果融合算法
- [ ] 动态权重调整
- [ ] A/B 测试

### 阶段 5：生产优化（2-4 周）

- [ ] 缓存优化
- [ ] 并行处理
- [ ] 监控和告警
- [ ] 文档完善

---

## 七、总结和建议

### 7.1 推荐方案

**短期（1-3 个月）**：
1. ✅ 实现 BM25 评分
2. ✅ 提供自定义评分函数接口
3. ✅ 支持基础向量搜索（暴力）

**中期（3-6 个月）**：
1. ✅ 实现 HNSW 索引
2. ✅ 集成预训练模型
3. ✅ 实现混合搜索

**长期（6-12 个月）**：
1. ✅ 向量量化
2. ✅ 自适应权重
3. ✅ 分布式支持

### 7.2 技术选型建议

| 场景 | 推荐方案 | 理由 |
|------|---------|------|
| 小规模数据（< 100万） | BM25 | 实现简单，性能足够 |
| 中等规模（100万-1000万） | BM25 + 暴力向量搜索 | 平衡性能和相关性 |
| 大规模（> 1000万） | BM25 + HNSW | 高性能，可扩展 |
| 实时搜索 | BM25 | 延迟最低 |
| 语义搜索 | 向量搜索 | 相关性最高 |
| 混合需求 | 混合搜索 | 兼顾精确匹配和语义理解 |

### 7.3 注意事项

1. **性能权衡**：向量搜索比关键词搜索慢 10-100 倍
2. **内存占用**：向量索引需要大量内存（每个文档 ~1KB）
3. **模型选择**：根据语言和领域选择合适的嵌入模型
4. **参数调优**：BM25 的 k1、b 和混合权重需要根据数据集调整
5. **缓存策略**：合理使用缓存可以显著提升性能

---

## 附录：代码示例

### A. 完整的 BM25 实现

```javascript
// src/index/bm25-complete.js
import { Index } from "../index.js";
import { create_object } from "../common.js";

export class BM25Index extends Index {
    constructor(options, _register) {
        super(options, _register);

        // BM25 参数
        this.k1 = options.k1 || 1.2;
        this.b = options.b || 0.75;

        // 统计数据
        this.docLengths = new Map();
        this.totalDocs = 0;
        this.avgDocLength = 0;
        this.termDocFreq = new Map();
        this.termTotalFreq = new Map();

        // 词频统计
        this.docTermFreqs = new Map();
    }

    add(id, content, _append, _skip_update) {
        const encoded = this.encoder.encode(content);
        const docLength = encoded.length;

        // 更新文档统计
        if (!_append) {
            this.docLengths.set(id, docLength);
            this.totalDocs++;
            this.updateAvgDocLength();

            // 统计词频
            const termFreqs = new Map();
            for (const term of encoded) {
                const freq = termFreqs.get(term) || 0;
                termFreqs.set(term, freq + 1);
            }
            this.docTermFreqs.set(id, termFreqs);

            // 更新词文档频率
            const uniqueTerms = new Set(encoded);
            for (const term of uniqueTerms) {
                const docFreq = this.termDocFreq.get(term) || 0;
                this.termDocFreq.set(term, docFreq + 1);

                const totalFreq = this.termTotalFreq.get(term) || 0;
                this.termTotalFreq.set(term, totalFreq + termFreqs.get(term));
            }
        }

        return super.add(id, content, _append, _skip_update);
    }

    updateAvgDocLength() {
        let total = 0;
        for (const len of this.docLengths.values()) {
            total += len;
        }
        this.avgDocLength = total / this.totalDocs;
    }

    search(query, limit, options) {
        const encodedQuery = this.encoder.encode(query);
        const results = new Map();

        for (const term of encodedQuery) {
            const postings = this.map.get(term);
            if (!postings) continue;

            const idf = this.calculateIDF(term);

            for (let score = 0; score < postings.length; score++) {
                for (const docId of postings[score]) {
                    const docLength = this.docLengths.get(docId) || 0;
                    const termFreqs = this.docTermFreqs.get(docId) || new Map();
                    const termFreq = termFreqs.get(term) || 0;

                    const bm25Score = idf * (termFreq * (this.k1 + 1)) /
                                           (termFreq + this.k1 * (1 - this.b + this.b * docLength / this.avgDocLength));

                    if (!results.has(docId)) {
                        results.set(docId, { score: 0, terms: [] });
                    }
                    results.get(docId).score += bm25Score;
                    results.get(docId).terms.push(term);
                }
            }
        }

        const sorted = Array.from(results.entries())
            .sort((a, b) => b[1].score - a[1].score)
            .slice(0, limit || 100);

        return sorted.map(([id, data]) => parseInt(id));
    }

    calculateIDF(term) {
        const docFreq = this.termDocFreq.get(term) || 0;
        return Math.log((this.totalDocs - docFreq + 0.5) / (docFreq + 0.5) + 1);
    }
}
```

### B. 使用示例

```javascript
import { BM25Index } from './src/index/bm25-complete.js';

// 创建 BM25 索引
const index = new BM25Index({
    k1: 1.2,
    b: 0.75,
    tokenize: 'strict',
    resolution: 9
});

// 添加文档
index.add(1, "The quick brown fox jumps over the lazy dog");
index.add(2, "A fast animal runs through the forest");
index.add(3, "The dog is sleeping on the couch");
index.add(4, "Quick brown foxes are fast animals");
index.add(5, "The lazy dog didn't chase the fox");

// 搜索
const results = index.search("fast fox", 10);
console.log(results);  // [4, 2, 1, 5, 3]
```

---

**文档版本**：1.0
**最后更新**：2026-02-04
**作者**：FlexSearch 技术分析团队
